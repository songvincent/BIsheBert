{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/transformers/model_doc/bert.html\n",
    "## https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_loader 的MyPro加载数据\n",
    "### bert_ner 中 有模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MyPro,convert_examples_to_features,create_batch_iter\n",
    "from bert_ner import Bert_Softmax\n",
    "# from bert_ner import Bert_Softmax\n",
    "import torch\n",
    "from transformers import BertConfig,AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evalutor import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-Nh', 'I-Nh', 'B-NDR', 'I-NDR']\n",
    "train_iter = create_batch_iter(\"train\",'../multi_data/multi_trainner.txt',12,label_list)\n",
    "\n",
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "bert_softmax = Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [10.0] * len(label_list)   #生成一维\n",
    "\n",
    "weight[0] = 1\n",
    "\n",
    "weight = torch.tensor(weight).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(weight,size_average=False)      #定义的损失函数，softmax以后求损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_optimizer = bert_softmax.named_parameters()\n",
    "\n",
    "# param_optimizer = list(bert_softmax.named_parameters())\n",
    "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "# optimizer_grouped_parameters = [\n",
    "#         {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "#         {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "# optimizer = AdamW(optimizer_grouped_parameters,lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 冻结部分参数\n",
    "\n",
    "unfreeze_layers = ['layer.11','bert.pooler','classifier.']\n",
    " \n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    print(name,param.size())\n",
    "\n",
    "print(\"*\"*30)\n",
    "print('\\n')\n",
    "\n",
    "for name ,param in bert_softmax.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    for ele in unfreeze_layers:\n",
    "        if ele in name:\n",
    "            param.requires_grad = True\n",
    "            break\n",
    "#验证一下\n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.size())\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉requires_grad = False的参数\n",
    "#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=0.1)\n",
    "lr = 0.0001\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(bert_softmax.parameters(), lr = 0.0001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_softmax.train()\n",
    "for e in range(5):\n",
    "    count = 0\n",
    "    if (e+1)%2 == 0:\n",
    "        lr = lr/2\n",
    "        optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)\n",
    "    \n",
    "    for step, batch in enumerate(train_iter):\n",
    "        count += 1\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        label_ids = label_ids.cuda()\n",
    "        out = bert_softmax(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "        \n",
    "        out1 = out.view(-1, out.size(2))\n",
    "        res1 = label_ids[0]\n",
    "        for i in range(1,len(label_ids)):\n",
    "            res1 = torch.cat((res1,label_ids[i]))\n",
    "        loss = criterion(out1,res1)\n",
    "        loss = loss/len(out)\n",
    "        \n",
    "        if count %5 == 0:\n",
    "            print('loss: ',loss)\n",
    "            out2 = torch.argmax(out,dim=2)\n",
    "            batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "            print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(str(e)+'：结束')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch_precision:0.9526  batch_recall:0.9731  batch_f1: 0.9628\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存模型\n",
    "# len(bert_softmax.state_dict())\n",
    "PATH = '../model_save/bert_softmax'\n",
    "torch.save(bert_softmax.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load model\n",
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "# bert_softmax = Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-Nh', 'I-Nh', 'B-NDR', 'I-NDR']\n",
    "eval_iter = create_batch_iter(\"train\",'../multi_data/multi_testner.txt',8,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load_model\n",
    "PATH = '../model_save/bert_softmax'\n",
    "model = Bert_Softmax(config,5).cuda()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "#### load_model \n",
    "# out = model(input_ids,segment_ids,input_mask)  \n",
    "        \n",
    "# out1 = out.view(-1, out.size(2))\n",
    "# res1 = label_ids[0]\n",
    "# for i in range(1,len(label_ids)):\n",
    "#     res1 = torch.cat((res1,label_ids[i]))\n",
    "# loss = criterion(out1,res1)\n",
    "# loss = loss/len(out)\n",
    "\n",
    "# if count %5 == 0:\n",
    "# print('loss: ',loss)\n",
    "# out2 = torch.argmax(out,dim=2)\n",
    "# batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "# print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [10.0] * len(label_list)   #生成一维\n",
    "\n",
    "weight[0] = 1\n",
    "\n",
    "weight = torch.tensor(weight).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(weight,size_average=False)      #定义的损失函数，softmax以后求损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iter = create_batch_iter(\"train\",'../multi_data/multi_testner.txt',8,label_list)\n",
    "# bert_softmax.train()\n",
    "for step, batch in enumerate(eval_iter):\n",
    "#     count += 1\n",
    "    input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "    input_ids = input_ids.cuda()\n",
    "    input_mask = input_mask.cuda()\n",
    "    segment_ids = segment_ids.cuda()\n",
    "    label_ids = label_ids.cuda()\n",
    "    out = model(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "\n",
    "    out1 = out.view(-1, out.size(2))\n",
    "    res1 = label_ids[0]\n",
    "    for i in range(1,len(label_ids)):\n",
    "        res1 = torch.cat((res1,label_ids[i]))\n",
    "    loss = criterion(out1,res1)\n",
    "    loss = loss/len(out)\n",
    "\n",
    "    \n",
    "    print('loss: ',loss)\n",
    "    out2 = torch.argmax(out,dim=2)\n",
    "    batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "    print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(input_mask[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_ids[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(input_ids[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #     label_true = []\n",
    "    #     y_pre = []\n",
    "#         loss = torch.tensor(0.0,requires_grad=True)\n",
    "#         for i in range(len(out)):\n",
    "#     #         label_true.append([label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ])\n",
    "#     #         y_pre.append([out[i][j].tolist() for j in range(512) if input_mask[i][j] == 1 ])\n",
    "            \n",
    "#             label_true = [label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "#             y_pre = [out[i][j].tolist() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "\n",
    "#             assert len(label_true) == len(y_pre)\n",
    "\n",
    "#             label_true = torch.tensor(label_true).cuda()\n",
    "#             y_pre = torch.tensor(y_pre).cuda()\n",
    "\n",
    "#             tmp_loss = criterion(y_pre, label_true)\n",
    "# #             tmp_loss = tmp_loss/len(y_pre)\n",
    "#             loss = loss+tmp_loss\n",
    "# #             loss.backward()\n",
    "# #             optimizer.backward(loss)\n",
    "    \n",
    "    \n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from redata_loader import MyPro,convert_examples_to_features,create_batch_iter\n",
    "from redata_loader import create_batch_iter\n",
    "from bert_ner import RE_Bert_Softmax\n",
    "# from bert_ner import Bert_Softmax\n",
    "import torch\n",
    "from transformers import BertConfig,AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {}\n",
    "tag2id['O'] = 0\n",
    "tag2id['traffic_in'] = 1\n",
    "tag2id['sell_drugs_to'] = 2\n",
    "tag2id['provide_shelter_for'] = 3\n",
    "tag2id['posess'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = create_batch_iter(\"train\",'../multi_data/multi_trainre.txt',12,tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "bert_softmax = RE_Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irsdc/songwenhui/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# weight = [10.0] * len(tag2id)   #生成一维\n",
    "# weight[0] = 1\n",
    "# weight = torch.tensor(weight).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(size_average=False)      #定义的损失函数，softmax以后求损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight torch.Size([21128, 768])\n",
      "bert.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "bert.pooler.dense.weight torch.Size([768, 768])\n",
      "bert.pooler.dense.bias torch.Size([768])\n",
      "classifier.weight torch.Size([5, 768])\n",
      "classifier.bias torch.Size([5])\n",
      "******************************\n",
      "\n",
      "\n",
      "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "bert.pooler.dense.weight torch.Size([768, 768])\n",
      "bert.pooler.dense.bias torch.Size([768])\n",
      "classifier.weight torch.Size([5, 768])\n",
      "classifier.bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "### 冻结部分参数\n",
    "\n",
    "unfreeze_layers = ['layer.11','bert.pooler','classifier.']\n",
    " \n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    print(name,param.size())\n",
    "\n",
    "print(\"*\"*30)\n",
    "print('\\n')\n",
    "\n",
    "for name ,param in bert_softmax.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    for ele in unfreeze_layers:\n",
    "        if ele in name:\n",
    "            param.requires_grad = True\n",
    "            break\n",
    "#验证一下\n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉requires_grad = False的参数\n",
    "#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=0.1)\n",
    "lr = 0.0001\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.4584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.0005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.0457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4685, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.7092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.1115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.2677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7066, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.6789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0：结束\n",
      "loss:  tensor(0.6264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.7276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.0266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3268, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.5074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4916, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.5400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "1：结束\n",
      "loss:  tensor(0.5180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4224, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5256, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.1956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.2838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "2：结束\n",
      "loss:  tensor(0.4731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4712, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.5872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1953, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7645, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.4289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "3：结束\n",
      "loss:  tensor(0.5068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(1.0528, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.2731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.9378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.8391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4171, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.0803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.6341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.5243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.4751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.7653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.2676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "loss:  tensor(0.3837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "4：结束\n"
     ]
    }
   ],
   "source": [
    "bert_softmax.train()\n",
    "for e in range(5):\n",
    "#     count = 0\n",
    "    if (e+1)%2 == 0:\n",
    "        lr = lr/2\n",
    "        optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)\n",
    "    \n",
    "    for step, batch in enumerate(train_iter):\n",
    "#         count += 1\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        label_ids = label_ids.cuda()\n",
    "        out = bert_softmax(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "        \n",
    "        loss = F.cross_entropy(out, label_ids)\n",
    "        \n",
    "#         out1 = out.view(-1, out.size(2))\n",
    "#         res1 = label_ids[0]\n",
    "#         for i in range(1,len(label_ids)):\n",
    "#             res1 = torch.cat((res1,label_ids[i]))\n",
    "#         loss = criterion(out,label_ids)\n",
    "        #loss = loss/len(out)\n",
    "        \n",
    "#         if count %5 == 0:\n",
    "        print('loss: ',loss)\n",
    "#             out2 = torch.argmax(out,dim=2)\n",
    "#             batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "#             print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(str(e)+'：结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
