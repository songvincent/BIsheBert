{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rawdata  --->  NER_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 原来是标注的原始文件，relations,entitys,等都有\n",
    "* 处理后是 source,target, 但是关系尚未标出 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 人名  Nh\n",
    "* 毒品 NDR\n",
    "* 其他都是O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O   0\n",
    "- traffic_in 1\n",
    "- sell_drugs_to 2\n",
    "- provide_shelter_for 3\n",
    "- posess          4     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {}\n",
    "tag2id['O'] = 0\n",
    "tag2id['traffic_in'] = 1\n",
    "tag2id['sell_drugs_to'] = 2\n",
    "tag2id['provide_shelter_for'] = 3\n",
    "tag2id['posess'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "\n",
    "filename = 'multi_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prepath+filename,'r',encoding='gbk') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(lines[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_label(start,end,sym,label_list):\n",
    "    for i in range(start,end):\n",
    "        if i == start:\n",
    "            label_list[i] = 'B-'+sym\n",
    "#             print(label_list[i])\n",
    "        else:\n",
    "            label_list[i] = 'I-'+sym\n",
    "#     print(start,end,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_lines = []\n",
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    if len(sentText) > 510:\n",
    "        continue\n",
    "#         sentText = sentText[:510]\n",
    "#     print(sentText)\n",
    "    label = ['O']*len(sentText)\n",
    "#     print(len(sentText),type(label))\n",
    "    entityMentions = con['entityMentions']\n",
    "    for entity in entityMentions:\n",
    "        if entity['label'] == 'Nh' or entity['label'] == 'NDR':\n",
    "#             print(entity['start'])\n",
    "            update_label(entity['start'],entity['end'],entity['label'],label)\n",
    "    ner_line['source'] = sentText\n",
    "    ner_line['target'] = label\n",
    "#     ner_line['relations'] = []\n",
    "#     relationMentions = con['relationMentions']\n",
    "#     for relamen in relationMentions:\n",
    "#         entity1 = relamen['em1Text']\n",
    "#         e1start = relamen['e1start']\n",
    "#         entity2 = relamen['em2Text']\n",
    "#         e2start = relamen['e21start']\n",
    "#         label = relamen['label']\n",
    "#         ner_line['relations'].append([str(e1start)+'-'+str(len(entity1),tag2id[label],str(e2start)+'-'+str(len(entity2)]))\n",
    "#         ner_line['relations'].append(tag2id[label])\n",
    "#         ner_line['relations'].append(str(e2start)+'-'+str(len(entity2)))\n",
    "        \n",
    "    ner_lines.append(ner_line)\n",
    "#     print(con['entityMentions'])\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines),len(ner_lines)  ###除去了两个特长序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_lines[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "with open(prepath+filename.split('.')[0]+'ner.txt','w+',encoding = 'utf-8') as f:\n",
    "    for line in ner_lines:\n",
    "        line_str = json.dumps(line)\n",
    "        f.write(line_str+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计字数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "\n",
    "filename = 'multi_trainner.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(prepath+filename,'r',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text = []\n",
    "for line in lines:\n",
    "    line= line.strip()\n",
    "    con = json.loads(line)\n",
    "    sentText = con['source']\n",
    "#     print(sentText)\n",
    "    count_text.append(len(sentText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(count_text)) ## bert 句子长度设为512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rawdata  --->  RE_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "filename = 'multi_test.txt'\n",
    "\n",
    "with open(prepath+filename,'r',encoding='gbk') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020)\n",
    "##  注意，因为随机数的存在每次产生的数据都可能不一样,所以利用随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_lines = []\n",
    "re_lines = []\n",
    "# labels = []\n",
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    relationMentions = con['relationMentions']\n",
    "    triples = []\n",
    "    tuples = []\n",
    "    entitys = []\n",
    "#     e1s = []\n",
    "#     e2s = []\n",
    "    for relationMention in relationMentions:\n",
    "        e1 = relationMention['em1Text']\n",
    "        e2 = relationMention['em2Text']\n",
    "        label = relationMention['label']\n",
    "        triples.append((label,e1,e2))\n",
    "        tuples.append((e1,e2))\n",
    "        entitys.append(e1)\n",
    "        entitys.append(e2)\n",
    "    length = len(entitys)   \n",
    "    for i in range(5):\n",
    "        t1 = random.randint(0,length-1)\n",
    "        e1 = entitys[t1]\n",
    "        t2 = random.randint(0,length-1)\n",
    "        e2 = entitys[t2]\n",
    "        if (e1,e2) in tuples or e1==e2:\n",
    "            continue\n",
    "        if ('O',e1,e2) not in triples:\n",
    "            triples.append(('O',e1,e2))\n",
    "            \n",
    "#     print(triples)\n",
    "    \n",
    "    for lee in triples:\n",
    "        re_line ={}\n",
    "        line_label = lee[0]\n",
    "        res_line = lee[1]+'，'+lee[2]+'。'+sentText\n",
    "        if len(res_line) >510:\n",
    "            continue\n",
    "        re_line['source'] = res_line\n",
    "        re_line['target'] = line_label\n",
    "        re_lines.append(re_line)\n",
    "#         re_lines.append(res_line)\n",
    "#         labels.append(line_label)\n",
    "#         print()\n",
    "\n",
    "        \n",
    "#     break\n",
    "        \n",
    "    \n",
    "#     entityMentions = con['entityMentions']\n",
    "#     entitys = []\n",
    "#     for entity in entityMentions:\n",
    "#         if entity['label'] == 'Nh' or entity['label'] == 'NDR':\n",
    "#             ent_pos = (entity['text'],entity['start'])\n",
    "#             entitys.append(ent_pos)\n",
    "# #     entitys = entitys\n",
    "#     length = len(entitys)\n",
    "#     for i in range(length):\n",
    "#         e1,e2,label = get_label(i,length,entitys,relationMentions)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(re_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle (re_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(re_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "with open(prepath+filename.split('.')[0]+'re.txt','w+',encoding = 'utf-8') as f:\n",
    "    for line in re_lines:\n",
    "        line_str = json.dumps(line)\n",
    "        f.write(line_str+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw_data --> Entity_Rela_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 训练集测试集需要统计到一起\n",
    "# entityss = []\n",
    "# ent2id = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {}\n",
    "tag2id['O'] = 0\n",
    "tag2id['traffic_in'] = 1\n",
    "tag2id['sell_drugs_to'] = 2\n",
    "tag2id['provide_shelter_for'] = 3\n",
    "tag2id['posess'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = 'multi_data/'\n",
    "filename = 'multi_test.txt'\n",
    "\n",
    "with open(prepath+filename,'r',encoding='gbk') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014\n"
     ]
    }
   ],
   "source": [
    "with open(prepath+'ent2id.json','r',encoding='utf-8') as fe:\n",
    "    ent2id = json.load(fe)\n",
    "print(len(ent2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_label(start,end,sym,label_list):\n",
    "    for i in range(start,end):\n",
    "        if i == start:\n",
    "            label_list[i] = 'B-'+sym\n",
    "#             print(label_list[i])\n",
    "        else:\n",
    "            label_list[i] = 'I-'+sym\n",
    "#     print(start,end,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_lines = []\n",
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    if len(sentText) > 510:\n",
    "        continue\n",
    "#         sentText = sentText[:510]\n",
    "#     print(sentText)\n",
    "    label = ['O']*len(sentText)\n",
    "#     print(len(sentText),type(label))\n",
    "    entityMentions = con['entityMentions']\n",
    "    for entity in entityMentions:\n",
    "        if entity['label'] == 'Nh' or entity['label'] == 'NDR':\n",
    "#             print(entity['start'])\n",
    "            update_label(entity['start'],entity['end'],entity['label'],label)\n",
    "    ner_line['source'] = sentText\n",
    "    ner_line['target'] = label\n",
    "    ner_line['relations'] = []\n",
    "    relationMentions = con['relationMentions']\n",
    "    for relamen in relationMentions:\n",
    "        entity1 = relamen['em1Text']\n",
    "        e1 = ent2id[entity1]\n",
    "#         entityss.append(entity1)\n",
    "#         e1start = relamen['e1start']\n",
    "        entity2 = relamen['em2Text']\n",
    "        e2 = ent2id[entity2]\n",
    "#         entityss.append(entity2)\n",
    "#         e2start = relamen['e21start']\n",
    "        label = relamen['label']\n",
    "        label = tag2id[label]\n",
    "        ner_line['relations'].append((e1,e2,label))\n",
    "        \n",
    "#         ner_line['relations'].append([str(e1start)+'-'+str(len(entity1),tag2id[label],str(e2start)+'-'+str(len(entity2)]))\n",
    "#         ner_line['relations'].append(tag2id[label])\n",
    "#         ner_line['relations'].append(str(e2start)+'-'+str(len(entity2)))\n",
    "        \n",
    "    ner_lines.append(ner_line)\n",
    "#     print(con['entityMentions'])\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(entityss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '经审理查明，2014年4月28日23时许，公安机关接群众举报，在本市江汉区江汉区永前三巷26号三楼将被告人平某抓获，从被告人平某的手提包内查获毒品甲基苯丙胺（俗称麻果、冰毒）17.85克。毒品已收缴。', 'target': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Nh', 'I-Nh', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Nh', 'I-Nh', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NDR', 'I-NDR', 'I-NDR', 'I-NDR', 'I-NDR', 'O', 'O', 'O', 'B-NDR', 'I-NDR', 'O', 'B-NDR', 'I-NDR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'relations': [(885, 13, 4)]}\n"
     ]
    }
   ],
   "source": [
    "print(ner_lines[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(prepath+'entitys.json','r',encoding='utf-8') as fe:\n",
    "#     ss = json.load(fe)\n",
    "# print(len(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "with open(prepath+filename.split('.')[0]+'_er.txt','w+',encoding = 'utf-8') as f:\n",
    "    for line in ner_lines:\n",
    "        line_str = json.dumps(line)\n",
    "        f.write(line_str+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save  ent2id  entityss\n",
    "'''\n",
    "set_entitys = list(set(entityss))\n",
    "idx = 0\n",
    "for ent in set_entitys:\n",
    "    ent2id[ent] = idx\n",
    "    idx += 1\n",
    "    \n",
    "assert len(set_entitys) == len(ent2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set_entitys),len(ent2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prepath+'entitys.json','w+',encoding = 'utf-8') as f:\n",
    "    json.dump(set_entitys,f,ensure_ascii=False)\n",
    "f.close()\n",
    "\n",
    "with open(prepath+'ent2id.json','w+',encoding = 'utf-8') as f:\n",
    "    json.dump(ent2id,f,ensure_ascii=False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw_data --> Joint data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关系\\角色 | 施动者 | 受动者\n",
    "-|-|-\n",
    "traffic_in | 1 | 2\n",
    "sell_drugs_to |3 |4\n",
    "provide_shelter_for |5 |6\n",
    "posess |7 |8\n",
    "O |0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_role = {}\n",
    "re_role['traffic_in'] = [1,2]\n",
    "re_role['sell_drugs_to'] = [3,4]\n",
    "re_role['provide_shelter_for'] = [5,6]\n",
    "re_role['posess'] = [7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "filename = 'multi_train.txt'\n",
    "\n",
    "with open(prepath+filename,'r',encoding='gbk') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_labels():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_lines = []\n",
    "re_lines = []\n",
    "# labels = []\n",
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    labels = ['O']*len(sentText)\n",
    "    \n",
    "    assert len(sentText) == len(labels)\n",
    "#     print(sentText)\n",
    "#     print(labels)\n",
    "#     break\n",
    "    \n",
    "    relationMentions = con['relationMentions']\n",
    "    triples = []\n",
    "    tuples = []\n",
    "    entitys = []\n",
    "#     e1s = []\n",
    "#     e2s = []\n",
    "    for relationMention in relationMentions:\n",
    "        e1 = relationMention['em1Text']\n",
    "        e2 = relationMention['em2Text']\n",
    "        label = relationMention['label']\n",
    "        triples.append((label,e1,e2))\n",
    "        tuples.append((e1,e2))\n",
    "        entitys.append(e1)\n",
    "        entitys.append(e2)\n",
    "    length = len(entitys)   \n",
    "    for i in range(5):\n",
    "        t1 = random.randint(0,length-1)\n",
    "        e1 = entitys[t1]\n",
    "        t2 = random.randint(0,length-1)\n",
    "        e2 = entitys[t2]\n",
    "        if (e1,e2) in tuples or e1==e2:\n",
    "            continue\n",
    "        if ('O',e1,e2) not in triples:\n",
    "            triples.append(('O',e1,e2))\n",
    "            \n",
    "#     print(triples)\n",
    "    break\n",
    "    for lee in triples:\n",
    "        re_line ={}\n",
    "        line_label = lee[0]\n",
    "        res_line = lee[1]+'，'+lee[2]+'。'+sentText\n",
    "        if len(res_line) >510:\n",
    "            continue\n",
    "        re_line['source'] = res_line\n",
    "        re_line['target'] = line_label\n",
    "        re_lines.append(re_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
