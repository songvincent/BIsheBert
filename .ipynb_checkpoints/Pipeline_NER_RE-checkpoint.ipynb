{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/transformers/model_doc/bert.html\n",
    "## https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_loader 的MyPro加载数据\n",
    "### bert_ner 中 有模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MyPro,convert_examples_to_features,create_batch_iter\n",
    "from bert_ner import Bert_Softmax\n",
    "# from bert_ner import Bert_Softmax\n",
    "import torch\n",
    "from transformers import BertConfig,AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from Evalutor import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-Nh', 'I-Nh', 'B-NDR', 'I-NDR']\n",
    "train_iter = create_batch_iter(\"train\",'../multi_data/multi_trainner.txt',12,label_list)\n",
    "\n",
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "bert_softmax = Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irsdc/songwenhui/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "weight = [10.0] * len(label_list)   #生成一维\n",
    "\n",
    "weight[0] = 1\n",
    "\n",
    "weight = torch.tensor(weight).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(weight,size_average=False)      #定义的损失函数，softmax以后求损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_optimizer = bert_softmax.named_parameters()\n",
    "\n",
    "# param_optimizer = list(bert_softmax.named_parameters())\n",
    "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "# optimizer_grouped_parameters = [\n",
    "#         {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "#         {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "# optimizer = AdamW(optimizer_grouped_parameters,lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight torch.Size([21128, 768])\n",
      "bert.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "bert.pooler.dense.weight torch.Size([768, 768])\n",
      "bert.pooler.dense.bias torch.Size([768])\n",
      "classifier.weight torch.Size([5, 768])\n",
      "classifier.bias torch.Size([5])\n",
      "******************************\n",
      "\n",
      "\n",
      "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "bert.pooler.dense.weight torch.Size([768, 768])\n",
      "bert.pooler.dense.bias torch.Size([768])\n",
      "classifier.weight torch.Size([5, 768])\n",
      "classifier.bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "### 冻结部分参数\n",
    "\n",
    "unfreeze_layers = ['layer.11','bert.pooler','classifier.']\n",
    " \n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    print(name,param.size())\n",
    "\n",
    "print(\"*\"*30)\n",
    "print('\\n')\n",
    "\n",
    "for name ,param in bert_softmax.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    for ele in unfreeze_layers:\n",
    "        if ele in name:\n",
    "            param.requires_grad = True\n",
    "            break\n",
    "#验证一下\n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.size())\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉requires_grad = False的参数\n",
    "#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=0.1)\n",
    "lr = 0.0001\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(bert_softmax.parameters(), lr = 0.0001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0：结束\n"
     ]
    }
   ],
   "source": [
    "bert_softmax.train()\n",
    "for e in range(1):\n",
    "    count = 0\n",
    "    if (e+1)%2 == 0:\n",
    "        lr = lr/2\n",
    "        optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)\n",
    "    \n",
    "    for step, batch in enumerate(train_iter):\n",
    "        count += 1\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        label_ids = label_ids.cuda()\n",
    "        out = bert_softmax(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "        break\n",
    "        out1 = out.view(-1, out.size(2))\n",
    "        res1 = label_ids[0]\n",
    "        for i in range(1,len(label_ids)):\n",
    "            res1 = torch.cat((res1,label_ids[i]))\n",
    "        loss = criterion(out1,res1)\n",
    "        loss = loss/len(out)\n",
    "        \n",
    "        if count %5 == 0:\n",
    "            print('loss: ',loss)\n",
    "            out2 = torch.argmax(out,dim=2)\n",
    "            batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "            print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(str(e)+'：结束')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(out)):\n",
    "        label_true = [label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "        y_pre = [out2[i][j].item() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch_precision:0.9526  batch_recall:0.9731  batch_f1: 0.9628\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_entitys(label_id):\n",
    "#     valid_pos = torch.nonzero(label_id).squeeze(1)\n",
    "#     entitys = []\n",
    "#     #         entitys2 = []\n",
    "#     flag = valid_pos[0]\n",
    "#     start = flag\n",
    "#     for vp in valid_pos[1:]:\n",
    "#         if vp -1 == flag:\n",
    "#             end = vp\n",
    "#         else:\n",
    "#             entity = [start.item(),(end+1).item()]\n",
    "#     #         entity = entity.replace(' ','')\n",
    "#             entitys.append(entity)\n",
    "#             start = vp\n",
    "\n",
    "#         flag = vp\n",
    "#     entity = [start.item(),(end+1).item()]\n",
    "#     # entity = entity.replace(' ','')\n",
    "#     entitys.append(entity)   ### 最后一个实体\n",
    "#     return entitys\n",
    "\n",
    "# get_entitys(label_ids[0])\n",
    "\n",
    "# out2 = torch.argmax(out,dim=2)\n",
    "# get_entitys(out2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存模型\n",
    "# len(bert_softmax.state_dict())\n",
    "PATH = '../model_save/bert_softmax'\n",
    "torch.save(bert_softmax.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load model\n",
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "# bert_softmax = Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-Nh', 'I-Nh', 'B-NDR', 'I-NDR']\n",
    "eval_iter = create_batch_iter(\"train\",'../multi_data/multi_testner.txt',8,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load_model\n",
    "PATH = '../model_save/bert_softmax'\n",
    "model = Bert_Softmax(config,5).cuda()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "#### load_model \n",
    "# out = model(input_ids,segment_ids,input_mask)  \n",
    "        \n",
    "# out1 = out.view(-1, out.size(2))\n",
    "# res1 = label_ids[0]\n",
    "# for i in range(1,len(label_ids)):\n",
    "#     res1 = torch.cat((res1,label_ids[i]))\n",
    "# loss = criterion(out1,res1)\n",
    "# loss = loss/len(out)\n",
    "\n",
    "# if count %5 == 0:\n",
    "# print('loss: ',loss)\n",
    "# out2 = torch.argmax(out,dim=2)\n",
    "# batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "# print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [10.0] * len(label_list)   #生成一维\n",
    "\n",
    "weight[0] = 1\n",
    "\n",
    "weight = torch.tensor(weight).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(weight,size_average=False)      #定义的损失函数，softmax以后求损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iter = create_batch_iter(\"train\",'../multi_data/multi_testner.txt',8,label_list)\n",
    "# bert_softmax.train()\n",
    "for step, batch in enumerate(eval_iter):\n",
    "#     count += 1\n",
    "    input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "    input_ids = input_ids.cuda()\n",
    "    input_mask = input_mask.cuda()\n",
    "    segment_ids = segment_ids.cuda()\n",
    "    label_ids = label_ids.cuda()\n",
    "    out = model(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "\n",
    "    out1 = out.view(-1, out.size(2))\n",
    "    res1 = label_ids[0]\n",
    "    for i in range(1,len(label_ids)):\n",
    "        res1 = torch.cat((res1,label_ids[i]))\n",
    "    loss = criterion(out1,res1)\n",
    "    loss = loss/len(out)\n",
    "\n",
    "    \n",
    "    print('loss: ',loss)\n",
    "    out2 = torch.argmax(out,dim=2)\n",
    "    batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "    print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(input_mask[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_ids[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(input_ids[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #     label_true = []\n",
    "    #     y_pre = []\n",
    "#         loss = torch.tensor(0.0,requires_grad=True)\n",
    "#         for i in range(len(out)):\n",
    "#     #         label_true.append([label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ])\n",
    "#     #         y_pre.append([out[i][j].tolist() for j in range(512) if input_mask[i][j] == 1 ])\n",
    "            \n",
    "#             label_true = [label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "#             y_pre = [out[i][j].tolist() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "\n",
    "#             assert len(label_true) == len(y_pre)\n",
    "\n",
    "#             label_true = torch.tensor(label_true).cuda()\n",
    "#             y_pre = torch.tensor(y_pre).cuda()\n",
    "\n",
    "#             tmp_loss = criterion(y_pre, label_true)\n",
    "# #             tmp_loss = tmp_loss/len(y_pre)\n",
    "#             loss = loss+tmp_loss\n",
    "# #             loss.backward()\n",
    "# #             optimizer.backward(loss)\n",
    "    \n",
    "    \n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Pipeline_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MyPro,convert_examples_to_features,create_batch_iter\n",
    "from bert_ner import Bert_Softmax\n",
    "# from bert_ner import Bert_Softmax\n",
    "import torch\n",
    "from transformers import BertConfig,AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from Evalutor import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-Nh', 'I-Nh', 'B-NDR', 'I-NDR']\n",
    "# train_iter = create_batch_iter(\"train\",'../multi_data/multi_trainner.txt',12,label_list)\n",
    "\n",
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "bert_softmax = Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../model_save/bert_softmax'\n",
    "model = Bert_Softmax(config,5).cuda()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [10.0] * len(label_list)   #生成一维\n",
    "\n",
    "weight[0] = 1\n",
    "\n",
    "weight = torch.tensor(weight).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(weight,size_average=False)      #定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer('../bert-base-chinese/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_iter = create_batch_iter(\"train\",'../multi_data/multi_testner.txt',8,label_list)\n",
    "# bert_softmax.train()\n",
    "lines = []\n",
    "train_iter = create_batch_iter(\"train\",'../multi_data/multi_trainner.txt',12,label_list)\n",
    "for step, batch in enumerate(train_iter):\n",
    "#     y_pres = []\n",
    "#     count += 1\n",
    "    input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "    input_ids = input_ids.cuda()\n",
    "    input_mask = input_mask.cuda()\n",
    "    segment_ids = segment_ids.cuda()\n",
    "    label_ids = label_ids.cuda()\n",
    "    out = model(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "    \n",
    "    out = torch.argmax(out,dim= 2)\n",
    "    \n",
    "    for i in range(len(out)):\n",
    "        label_true = [label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "        y_pre = [out[i][j].tolist() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "        y_pre = torch.tensor(y_pre)\n",
    "        valid_pos = torch.nonzero(y_pre).squeeze(1)\n",
    "        \n",
    "        entitys = []\n",
    "#         entitys2 = []\n",
    "        flag = valid_pos[0]\n",
    "        start = flag\n",
    "        for vp in valid_pos[1:]:\n",
    "            if vp -1 == flag:\n",
    "                end = vp\n",
    "            else:\n",
    "                entity = tokenizer.decode(input_ids[i][start:end+1])\n",
    "                entity = entity.replace(' ','')\n",
    "                entitys.append(entity)\n",
    "                start = vp\n",
    "        \n",
    "            flag = vp\n",
    "        entity = tokenizer.decode(input_ids[i][start:valid_pos[-1]+1])\n",
    "        entity = entity.replace(' ','')\n",
    "        entitys.append(entity)   ### 最后一个实体\n",
    "#         print(entitys)\n",
    "        context = tokenizer.decode(input_ids[i][:len(y_pre)][1:-1])\n",
    "        context = context.replace(' ','')\n",
    "#         context = context[1:-1]\n",
    "        \n",
    "        \n",
    "        entitys = list(set(entitys))   ### 去重，无所谓顺序，因为两两实体都会进行组合\n",
    "#         e1_e2 = []\n",
    "        e_len = len(entitys)\n",
    "        for i in range(e_len):\n",
    "            e1 = entitys[i]\n",
    "            for j in range(e_len):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                e2 = entitys[j]\n",
    "                line = e1+'，'+e2+'。'+context\n",
    "                lines.append(line)\n",
    "#                 print(line)\n",
    "#                 e1_e2.append([e1,e2])\n",
    "\n",
    "                \n",
    "#         print(e1_e2)\n",
    "#         print(context)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         y_pres.append()\n",
    "        \n",
    "#         break\n",
    "        \n",
    "    \n",
    "    \n",
    "#     break\n",
    "\n",
    "    '''out1 = out.view(-1, out.size(2))\n",
    "    res1 = label_ids[0]\n",
    "    for i in range(1,len(label_ids)):\n",
    "        res1 = torch.cat((res1,label_ids[i]))\n",
    "    loss = criterion(out1,res1)\n",
    "    loss = loss/len(out)\n",
    "\n",
    "    \n",
    "    print('loss: ',loss)\n",
    "    out2 = torch.argmax(out,dim=2)\n",
    "    batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "    print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/tmp.txt','r',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line for line in lines if len(json.loads(line))<=510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_lines = []\n",
    "for line in lines:\n",
    "    t = {}\n",
    "    t['source'] = json.loads(line)\n",
    "    t['target'] = 'O'\n",
    "    re_lines.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(re_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "with open('tmp/tmp2.txt','w+',encoding = 'utf-8') as f:\n",
    "    for line in tqdm(re_lines):\n",
    "        line_str = json.dumps(line)\n",
    "        f.write(line_str+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from redata_loader import MyPro,convert_examples_to_features,create_batch_iter\n",
    "from redata_loader import create_batch_iter\n",
    "from bert_ner import RE_Bert_Softmax\n",
    "# from bert_ner import Bert_Softmax\n",
    "import torch\n",
    "from transformers import BertConfig,AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from Evalutor import re_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {}\n",
    "tag2id['O'] = 0\n",
    "tag2id['traffic_in'] = 1\n",
    "tag2id['sell_drugs_to'] = 2\n",
    "tag2id['provide_shelter_for'] = 3\n",
    "tag2id['posess'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = create_batch_iter(\"train\",'../multi_data/multi_trainre.txt',16,tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "bert_softmax = RE_Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight = [10.0] * len(tag2id)   #生成一维\n",
    "# weight[0] = 1\n",
    "# weight = torch.tensor(weight).cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(size_average=False)      #定义的损失函数，softmax以后求损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 冻结部分参数\n",
    "\n",
    "unfreeze_layers = ['layer.11','bert.pooler','classifier.']\n",
    " \n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    print(name,param.size())\n",
    "\n",
    "print(\"*\"*30)\n",
    "print('\\n')\n",
    "\n",
    "for name ,param in bert_softmax.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    for ele in unfreeze_layers:\n",
    "        if ele in name:\n",
    "            param.requires_grad = True\n",
    "            break\n",
    "#验证一下\n",
    "for name, param in bert_softmax.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉requires_grad = False的参数\n",
    "#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=0.1)\n",
    "lr = 0.0002\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_softmax.train()\n",
    "for e in range(8):\n",
    "    count = 0\n",
    "    if (e+1)%2 == 0:\n",
    "        lr = lr/2\n",
    "        optimizer = AdamW(filter(lambda p: p.requires_grad, bert_softmax.parameters()), lr=lr,weight_decay = 0.1)\n",
    "    \n",
    "    for step, batch in enumerate(train_iter):\n",
    "        count += 1\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        label_ids = label_ids.cuda()\n",
    "        out = bert_softmax(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "        \n",
    "        loss = F.cross_entropy(out, label_ids)\n",
    "#         break\n",
    "        \n",
    "#         out1 = out.view(-1, out.size(2))\n",
    "#         res1 = label_ids[0]\n",
    "#         for i in range(1,len(label_ids)):\n",
    "#             res1 = torch.cat((res1,label_ids[i]))\n",
    "#         loss = criterion(out,label_ids)\n",
    "        #loss = loss/len(out)\n",
    "        \n",
    "        if count %5 == 0:\n",
    "            print('loss: ',loss)\n",
    "#             out2 = torch.argmax(out,dim=2)\n",
    "            batch_precision,batch_recall,batch_f1 = re_evaluate(out,label_ids)\n",
    "            print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(str(e)+'：结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.00 0.8642 0.9167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存模型\n",
    "# len(bert_softmax.state_dict())\n",
    "PATH = '../model_save/re_bert_softmax'\n",
    "torch.save(bert_softmax.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline 之RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from redata_loader import MyPro,convert_examples_to_features,create_batch_iter\n",
    "from redata_loader import create_batch_iter\n",
    "from bert_ner import RE_Bert_Softmax\n",
    "# from bert_ner import Bert_Softmax\n",
    "import torch\n",
    "from transformers import BertConfig,AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from Evalutor import re_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {}\n",
    "tag2id['O'] = 0\n",
    "tag2id['traffic_in'] = 1\n",
    "tag2id['sell_drugs_to'] = 2\n",
    "tag2id['provide_shelter_for'] = 3\n",
    "tag2id['posess'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag = []\n",
    "id2tag.append('O')\n",
    "id2tag.append('traffic_in')\n",
    "id2tag.append('sell_drugs_to')\n",
    "id2tag.append('provide_shelter_for')\n",
    "id2tag.append('posess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = create_batch_iter(\"train\",'tmp/tmp2.txt',16,tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "bert_softmax = RE_Bert_Softmax(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RE_Bert_Softmax(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../model_save/re_bert_softmax'\n",
    "rmodel = RE_Bert_Softmax(config,5).cuda()\n",
    "rmodel.load_state_dict(torch.load(PATH))\n",
    "rmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer('../bert-base-chinese/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lines = []\n",
    "for step, batch in enumerate(train_iter):\n",
    "#     count += 1\n",
    "    input_ids, input_mask, segment_ids, label_ids = batch   ##(batch_size,512)\n",
    "    input_ids = input_ids.cuda()\n",
    "    input_mask = input_mask.cuda()\n",
    "    segment_ids = segment_ids.cuda()\n",
    "    label_ids = label_ids.cuda()\n",
    "    out = rmodel(input_ids,segment_ids,input_mask)  #[batch_size,seq_len+2(512)]\n",
    "    out = torch.softmax(out,dim=1)\n",
    "    out = torch.argmax(out,dim = 1)\n",
    "    for i in range(len(out)):\n",
    "        label_true = [1 for j in range(512) if input_mask[i][j] == 1 ] ## 检验有效长度\n",
    "        length = len(label_true)\n",
    "        tag = id2tag[out[i]]\n",
    "        context = tokenizer.decode(input_ids[i][1:length-1])\n",
    "        context = context.replace(' ','')\n",
    "        res_line = {}\n",
    "        res_line['source'] = context\n",
    "        res_line['target'] = tag\n",
    "        \n",
    "        res_lines.append(res_line)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18548"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18548/18548 [00:00<00:00, 99802.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "with open('tmp/result.txt','w+',encoding = 'utf-8') as f:\n",
    "    for line in tqdm(res_lines):\n",
    "        line_str = json.dumps(line)\n",
    "        f.write(line_str+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline 最后预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evalutor import pipe_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "filename = 'multi_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prepath+filename,'r',encoding='gbk') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer('../bert-base-chinese/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_lines = []\n",
    "# re_lines = []\n",
    "# labels = []\n",
    "true_infor = {}\n",
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    relationMentions = con['relationMentions']\n",
    "    triples = []\n",
    "    tuples = []\n",
    "    entitys = []\n",
    "#     e1s = []\n",
    "#     e2s = []\n",
    "    for relationMention in relationMentions:\n",
    "        e1 = relationMention['em1Text']\n",
    "        e2 = relationMention['em2Text']\n",
    "        label = relationMention['label']\n",
    "        triples.append((label,e1,e2))\n",
    "        tuples.append((e1,e2))\n",
    "        entitys.append(e1)\n",
    "        entitys.append(e2)\n",
    "        \n",
    "    senttokens = list(sentText)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(senttokens)\n",
    "    sentText = tokenizer.decode(input_ids)\n",
    "    sentText = sentText.replace(' ','')\n",
    "    true_infor[sentText] = triples\n",
    "#     break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_infor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/result.txt','r',encoding='gbk') as f:\n",
    "    mlines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18548"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "etotal = [0.0,0.0,0.0,0.0]  ### tp,tn,fp,fn\n",
    "for line in mlines:\n",
    "    line_dict = json.loads(line)\n",
    "    source = line_dict['source']\n",
    "    label = line_dict['target']\n",
    "    so_list = source.split('。',1)\n",
    "    so1 = so_list[1].replace('[[UNK][UNK][UNK]]','[UNK]')\n",
    "    \n",
    "    if so1 not in true_infor:\n",
    "        continue\n",
    "    Tlabels = true_infor[so1]\n",
    "#     print(Tlabels)   ### e.g. [('posess', '欧某某', '甲基苯丙胺'), ('posess', '欧某某', '麻黄碱'), ('posess', '欧某某', '巴比妥')]\n",
    "    \n",
    "    so_0 = so_list[0]\n",
    "    e1_e2 = so_0.split('，')\n",
    "    pre_infor = (label,e1_e2[0],e1_e2[1])\n",
    "#     print(pre_infor)   ###e.g. ('posess', '欧某某', '甲基苯丙胺')\n",
    "    \n",
    "    eva = pipe_evaluate(pre_infor,Tlabels)\n",
    "    etotal = [ii+jj for ii,jj in zip(etotal,eva)]\n",
    "#     print(etotal)\n",
    "#     break\n",
    "    \n",
    "#     aa = aa.replace('[[UNK][UNK][UNK]]','[UNK]')\n",
    "#     if so1 not in true_infor:\n",
    "#         print(so1)\n",
    "    \n",
    "    \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.29484064599113907\n",
      "recall:  0.9885002395783421\n",
      "f1:  0.4542051959489211\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn = etotal\n",
    "p = tp/(tp+fp)\n",
    "r = tp/(tp+fn)\n",
    "f1 = 2*p*r/(p+r)\n",
    "print('precision: ',tp/(tp+fp))   ## 0.2984\n",
    "print('recall: ',tp/(tp+fn))    ## 0.9885\n",
    "print('f1: ',f1)                ## 0.4542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2063.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4934.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29484064599113907"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9885002395783421"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in true_infor.items():\n",
    "    if k[:9] == '同年11月3日10时许，':\n",
    "        k1 = k\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中山市第二市区人民检察院指控，2013年9月4日，被告人欧某某1受周某（另案处理）雇请，帮其从广东省广州市运输毒品至广西南宁市朗东车站交给“烧某某”（另案处理）。同年9月5日晚9时30分许，被告人欧某某1从广州市番禺区将毒品带至我市东凤镇金怡南路如锋药店门前路段，因形迹可疑被公安人员抓获，公安人员当场在其挂包内查获麻黄碱1包（净重0.55克）、巴比妥1包（净重0.17克）、甲基苯丙胺1包（净重0.09克）以及锡纸条、吸管各1条，并从其背包查获甲基苯丙胺3包（共净重49.72克）、氯胺酮2包（共净重1.81克）。公诉机关当庭宣读并出示了公安机关出具的抓获经过、缴获经过、搜查笔录、现场图及现场照片、《理化检验报告》、户籍证明等相关书证、证人莫某某、李某某的证言及辨认笔录、证人黄某某、欧某某的证言、被告人欧某某1的供述及辨认笔录等证据以证实上述指控。公诉机关据此认为，被告人欧某某1无视国家法律，运输毒品甲基苯丙胺、氯胺酮，其行为触犯了《中华人民共和国刑法》第三百四十七条第三款之规定，应当以运输毒品罪追究其刑事责任。提请本院依法惩处。\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    if sentText[:14] == '中山市第二市区人民检察院指控':\n",
    "        print(sentText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
