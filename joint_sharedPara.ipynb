{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MyPro,convert_examples_to_features,create_batch_iter\n",
    "# from bert_ner import Bert_Softmax\n",
    "# from bert_ner import Bert_Softmax\n",
    "import torch\n",
    "from transformers import BertConfig,AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from Evalutor import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建数据entitys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multi_data/entitys.json','r',encoding='utf-8') as f:\n",
    "    entitys = json.load(f)\n",
    "f.close()\n",
    "print(len(entitys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {}\n",
    "tag2id['O'] = 0\n",
    "tag2id['traffic_in'] = 1\n",
    "tag2id['sell_drugs_to'] = 2\n",
    "tag2id['provide_shelter_for'] = 3\n",
    "tag2id['posess'] = 4\n",
    "id2tag = ['O','traffic_in','sell_drugs_to','provide_shelter_for','posess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JS_Model(BertPreTrainedModel):\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 num_tag):\n",
    "        super(JS_Model, self).__init__(config)\n",
    "        self.bert = BertModel.from_pretrained('../bert-base-chinese/', config=config) #.cuda()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_tag)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                token_type_ids,\n",
    "                attention_mask,mode):\n",
    "\n",
    "        bert_encode = self.bert(input_ids, attention_mask, token_type_ids)  ## \n",
    "#         bert_encode = torch.tensor(bert_encode).cuda()\n",
    "        if mode ==\"ner\":\n",
    "            bert_encode0 = bert_encode[0].cuda()\n",
    "            output = self.classifier(bert_encode0)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "        elif mode == \"re\":\n",
    "            bert_encode1 = bert_encode[1].cuda()\n",
    "            output = self.classifier(bert_encode1)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model --->Shared Parameters\n",
    "'''\n",
    "\n",
    "\n",
    "config = BertConfig.from_json_file('../bert-base-chinese/bert_config.json')\n",
    "model = JS_Model(config,5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 冻结部分参数\n",
    "\n",
    "unfreeze_layers = ['layer.11','bert.pooler','classifier.']\n",
    " \n",
    "for name, param in model.named_parameters():\n",
    "    print(name,param.size())\n",
    "\n",
    "print(\"*\"*30)\n",
    "print('\\n')\n",
    "\n",
    "for name ,param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    for ele in unfreeze_layers:\n",
    "        if ele in name:\n",
    "            param.requires_grad = True\n",
    "            break\n",
    "#验证一下\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉requires_grad = False的参数\n",
    "'''\n",
    "  #### 优化器\n",
    "'''\n",
    "lr = 0.0001\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr,weight_decay = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 涉及到NER的参数/变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SP_data_loader import create_batch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset\n",
    "label_list = ['O', 'B-Nh', 'I-Nh', 'B-NDR', 'I-NDR']\n",
    "train_iter = create_batch_iter(\"train\",'multi_data/multi_train_er.txt',12,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_iter):\n",
    "# #     count += 1\n",
    "# #     input_ids, input_mask, segment_ids, label_ids,others = batch   ##(batch_size,512)\n",
    "# #     break\n",
    "\n",
    "# others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [10.0] * len(label_list)   #生成一维\n",
    "weight[0] = 1\n",
    "weight = torch.tensor(weight).cuda()\n",
    "criterion = nn.NLLLoss(weight,size_average=False)      #定义的损失函数，softmax以后求损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 涉及到RE的参数/变量/函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer('../bert-base-chinese/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multi_data/multi_train_er.txt','r',encoding='utf-8') as f:\n",
    "    flines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_tag = [json.loads(line) for line in flines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_re_lines(out,label_ids,input_mask):\n",
    "    out = torch.argmax(out,dim= 2)\n",
    "    lines = []\n",
    "    for i in range(len(out)):\n",
    "        s_lines = []\n",
    "        label_true = [label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "        y_pre = [out[i][j].tolist() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "        y_pre = torch.tensor(y_pre)\n",
    "        valid_pos = torch.nonzero(y_pre).squeeze(1)\n",
    "\n",
    "        entitys = []\n",
    "#         entitys2 = []\n",
    "        flag = valid_pos[0]\n",
    "        start = flag\n",
    "        end=start\n",
    "        for vp in valid_pos[1:]:\n",
    "            if vp -1 == flag:\n",
    "                end = vp\n",
    "            elif start==end:\n",
    "                continue\n",
    "            else:\n",
    "                entity = tokenizer.decode(input_ids[i][start:end+1])\n",
    "                entity = entity.replace(' ','')\n",
    "                if entity == '':\n",
    "                    continue\n",
    "                entitys.append(entity)\n",
    "                start = vp\n",
    "\n",
    "            flag = vp\n",
    "        entity = tokenizer.decode(input_ids[i][start:valid_pos[-1]+1])\n",
    "        entity = entity.replace(' ','')\n",
    "        entitys.append(entity)   ### 最后一个实体\n",
    "#         print(entitys)\n",
    "        context = tokenizer.decode(input_ids[i][:len(y_pre)][1:-1])\n",
    "        context = context.replace(' ','')\n",
    "#         context = context[1:-1]\n",
    "\n",
    "\n",
    "        entitys = list(set(entitys))   ### 去重，无所谓顺序，因为两两实体都会进行组合\n",
    "#         e1_e2 = []\n",
    "        e_len = len(entitys)\n",
    "        for i in range(e_len):\n",
    "            e1 = entitys[i]\n",
    "            for j in range(e_len):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                e2 = entitys[j]\n",
    "                line = e1+'，'+e2 #+'。'+context\n",
    "                s_lines.append(line)\n",
    "        lines.append(s_lines)\n",
    "                \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids[0].shape\n",
    "\n",
    "# x = torch.tensor([0]).cuda()\n",
    "\n",
    "# len(segment_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = create_re_lines(out,label_ids,input_mask)\n",
    "\n",
    "# print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_trip(others):\n",
    "    valid_tris = []\n",
    "    for other in others:\n",
    "        valid_tri = []\n",
    "        for eel in other:\n",
    "\n",
    "            if eel[2] == 0:\n",
    "                break\n",
    "            valid_tri.append((entitys[eel[0]],entitys[eel[1]],eel[2].item()))\n",
    "        valid_tris.append(valid_tri)\n",
    "        \n",
    "    return valid_tris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_tris = get_true_trip(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 比较二给定的双实体 获得在原句中具有关系\n",
    "## bi --> (pre_e1,pre_e2)  \n",
    "## tris --> [(e1,e2,rela),...]\n",
    "def get_rela(bi,tris):\n",
    "    \n",
    "    bi = bi.split('，')\n",
    "#     print(bi)\n",
    "#     print(tris)\n",
    "    for tri in tris:\n",
    "#         print(tri)\n",
    "#         tri = tri.split(',')\n",
    "        if bi[0] == tri[0] and bi[1] == tri[1]:\n",
    "            return tri[2]\n",
    "        \n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## segment_ids 不需要更新 因为全为0\n",
    "def handle_ids_mask_seg(ids,mask,in_id): ## in_id [CLS] 习某某，何某某。\n",
    "    length = len(in_id)\n",
    "    \n",
    "    in_id = torch.tensor(in_id).cuda()\n",
    "    new_ids = torch.cat((in_id,ids[1:]))[:512]\n",
    "    \n",
    "    _mask = torch.tensor([1]*length).cuda()\n",
    "    new_mask = torch.cat((_mask,mask[1:]))[:512]\n",
    "    \n",
    "#     _seg = torch.tensor([0]*length).cuda()\n",
    "#     new_seg = torch.cat((_seg))   seg不用变  因为全0\n",
    "    return new_ids,new_mask\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_id_seg_mask_label(lines,true_tris,input_ids,input_mask,segment_ids):\n",
    "    assert len(lines) == len(true_tris)\n",
    "\n",
    "    length = len(lines)\n",
    "\n",
    "    new_ids = []\n",
    "    new_masks = []\n",
    "    new_seg_ids = []\n",
    "    new_labels = []\n",
    "    for i in range(length):\n",
    "#         print(float(i))\n",
    "        input_id = input_ids[i]\n",
    "        input_m = input_mask[i]\n",
    "        segment_id = segment_ids[i]\n",
    "        line = lines[i]\n",
    "        true_tri = true_tris[i]\n",
    "    #     print(true_tri)\n",
    "        for l in line:\n",
    "    #         print(true_tri)\n",
    "            label = get_rela(l,true_tri)\n",
    "    #         if label != 0:\n",
    "#             print(label)\n",
    "            tokens = [\"[CLS]\"] + list(l+'。')\n",
    "            in_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    #             print(l)\n",
    "    #             print(tokens)\n",
    "    #             print(in_id)\n",
    "            assert len(tokens) == len(in_id)\n",
    "            new_id,new_mask = handle_ids_mask_seg(input_id,input_m,in_id)\n",
    "\n",
    "            assert Counter(new_id.tolist())[0] == Counter(new_mask.tolist())[0]\n",
    "\n",
    "            new_ids.append(new_id.tolist())\n",
    "            new_masks.append(new_mask.tolist())\n",
    "            new_seg_ids.append(segment_id.tolist())\n",
    "            new_labels.append(label)\n",
    "\n",
    "    re_len = len(new_ids)\n",
    "    index = list(range(re_len))\n",
    "    random.shuffle(index)\n",
    "\n",
    "    new_idss = [new_ids[i] for i in index]\n",
    "    new_maskss = [new_masks[i] for i in index]\n",
    "    new_seg_idss = [new_seg_ids[i] for i in index]\n",
    "    new_labelss = [new_labels[i] for i in index]\n",
    "\n",
    "    new_ids = torch.tensor(new_idss).cuda()\n",
    "    new_masks = torch.tensor(new_maskss).cuda()\n",
    "    new_seg_ids = torch.tensor(new_seg_idss).cuda()\n",
    "    new_labels = torch.tensor(new_labelss).cuda()\n",
    "    \n",
    "    return new_ids,new_masks,new_seg_ids,new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(lines) == len(true_tris)\n",
    "\n",
    "# length = len(lines)\n",
    "\n",
    "# new_ids = []\n",
    "# new_masks = []\n",
    "# new_seg_ids = []\n",
    "# new_labels = []\n",
    "# for i in range(length):\n",
    "#     print(float(i))\n",
    "#     input_id = input_ids[i]\n",
    "#     input_m = input_mask[i]\n",
    "#     segment_id = segment_ids[i]\n",
    "#     line = lines[i]\n",
    "#     true_tri = true_tris[i]\n",
    "# #     print(true_tri)\n",
    "#     for l in line:\n",
    "# #         print(true_tri)\n",
    "#         label = get_rela(l,true_tri)\n",
    "# #         if label != 0:\n",
    "#         print(label)\n",
    "#         tokens = [\"[CLS]\"] + list(l+'。')\n",
    "#         in_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# #             print(l)\n",
    "# #             print(tokens)\n",
    "# #             print(in_id)\n",
    "#         assert len(tokens) == len(in_id)\n",
    "#         new_id,new_mask = handle_ids_mask_seg(input_id,input_m,in_id)\n",
    "\n",
    "#         assert Counter(new_id.tolist())[0] == Counter(new_mask.tolist())[0]\n",
    "        \n",
    "#         new_ids.append(new_id.tolist())\n",
    "#         new_masks.append(new_mask.tolist())\n",
    "#         new_seg_ids.append(segment_id.tolist())\n",
    "#         new_labels.append(label)\n",
    "\n",
    "# #             break\n",
    "# #         print(label)\n",
    "        \n",
    "\n",
    "# import random\n",
    "\n",
    "# re_len = len(new_ids)\n",
    "# index = list(range(re_len))\n",
    "# random.shuffle(index)\n",
    "\n",
    "# new_idss = [new_ids[i] for i in index]\n",
    "# new_maskss = [new_masks[i] for i in index]\n",
    "# new_seg_idss = [new_seg_ids[i] for i in index]\n",
    "# new_labelss = [new_labels[i] for i in index]\n",
    "\n",
    "# new_ids = torch.tensor(new_idss).cuda()\n",
    "# new_masks = torch.tensor(new_maskss).cuda()\n",
    "# new_seg_ids = torch.tensor(new_seg_idss).cuda()\n",
    "# new_labels = torch.tensor(new_labelss).cuda()\n",
    "\n",
    "# # out = model(input_ids,segment_ids,input_mask,\"ner\")  #[batch_size,seq_len+2(512)]\n",
    "# re_out = model(new_ids,new_seg_ids,new_masks,'re')\n",
    "\n",
    "# loss1 = F.cross_entropy(re_out, new_labels)\n",
    "\n",
    "# print(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# Counter(new_id.tolist())[0]\n",
    "\n",
    "# Counter(new_mask.tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1):\n",
    "    count = 0\n",
    "    if (e+1)%2 == 0:\n",
    "        lr = lr/2\n",
    "        optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr,weight_decay = 0.1)\n",
    "    \n",
    "    for step, batch in enumerate(train_iter):\n",
    "        count += 1\n",
    "        \n",
    "        input_ids, input_mask, segment_ids, label_ids,others = batch   ##(batch_size,512)\n",
    "        \n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        label_ids = label_ids.cuda()\n",
    "        out = model(input_ids,segment_ids,input_mask,\"ner\")  #[batch_size,seq_len+2(512)]\n",
    "        \n",
    "        '''\n",
    "        计算loss\n",
    "        '''\n",
    "\n",
    "        out1 = out.view(-1, out.size(2))\n",
    "        res1 = label_ids[0]\n",
    "        for i in range(1,len(label_ids)):\n",
    "            res1 = torch.cat((res1,label_ids[i]))\n",
    "        loss = criterion(out1,res1)\n",
    "        loss = loss/len(out)\n",
    "        print(loss)\n",
    "        if loss <10.0:\n",
    "            \n",
    "#             lines = create_re_lines(out,label_ids,input_mask)\n",
    "            break\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(str(e)+'：结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1):\n",
    "    count = 0\n",
    "    if (e+1)%2 == 0:\n",
    "        lr = lr/2\n",
    "        optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr,weight_decay = 0.1)\n",
    "    \n",
    "    for step, batch in enumerate(train_iter):\n",
    "        count += 1\n",
    "        \n",
    "        input_ids, input_mask, segment_ids, label_ids,others = batch   ##(batch_size,512)\n",
    "        \n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        label_ids = label_ids.cuda()\n",
    "        out = model(input_ids,segment_ids,input_mask,\"ner\")  #[batch_size,seq_len+2(512)]\n",
    "        \n",
    "        '''\n",
    "        计算loss\n",
    "        '''\n",
    "\n",
    "        out1 = out.view(-1, out.size(2))\n",
    "        res1 = label_ids[0]\n",
    "        for i in range(1,len(label_ids)):\n",
    "            res1 = torch.cat((res1,label_ids[i]))\n",
    "        loss1 = criterion(out1,res1)\n",
    "        loss1 = loss1/len(out)\n",
    "        \n",
    "        if loss1 <5.0:\n",
    "            print(\"re loss\")\n",
    "            lines = create_re_lines(out,label_ids,input_mask)\n",
    "            true_tris = get_true_trip(others)\n",
    "\n",
    "            new_ids,new_masks,new_seg_ids,new_label = get_new_id_seg_mask_label(lines,true_tris,input_ids,input_mask,segment_ids)\n",
    "            re_out = model(new_ids,new_seg_ids,new_masks,'re')\n",
    "            loss2 = F.cross_entropy(re_out, new_labels)\n",
    "        else:\n",
    "            loss2 = loss1\n",
    "        \n",
    "        loss = 0.5*(loss1+loss2)\n",
    "        \n",
    "        print(loss)\n",
    "#         print(loss)\n",
    "#         if loss <10.0:\n",
    "            \n",
    "# #             lines = create_re_lines(out,label_ids,input_mask)\n",
    "#             break\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        产生re数据\n",
    "        '''\n",
    "        \n",
    "#         lines = create_re_lines(out,label_ids,input_mask)\n",
    "#         out = torch.argmax(out,dim= 2)\n",
    "#         lines = []\n",
    "#         for i in range(len(out)):\n",
    "#             label_true = [label_ids[i][j].item() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "#             y_pre = [out[i][j].tolist() for j in range(512) if input_mask[i][j] == 1 ]\n",
    "#             y_pre = torch.tensor(y_pre)\n",
    "#             valid_pos = torch.nonzero(y_pre).squeeze(1)\n",
    "\n",
    "#             entitys = []\n",
    "#     #         entitys2 = []\n",
    "#             flag = valid_pos[0]\n",
    "#             start = flag\n",
    "#             for vp in valid_pos[1:]:\n",
    "#                 if vp -1 == flag:\n",
    "#                     end = vp\n",
    "#                 else:\n",
    "#                     entity = tokenizer.decode(input_ids[i][start:end+1])\n",
    "#                     entity = entity.replace(' ','')\n",
    "#                     entitys.append(entity)\n",
    "#                     start = vp\n",
    "\n",
    "#                 flag = vp\n",
    "#             entity = tokenizer.decode(input_ids[i][start:valid_pos[-1]+1])\n",
    "#             entity = entity.replace(' ','')\n",
    "#             entitys.append(entity)   ### 最后一个实体\n",
    "#     #         print(entitys)\n",
    "#             context = tokenizer.decode(input_ids[i][:len(y_pre)][1:-1])\n",
    "#             context = context.replace(' ','')\n",
    "#     #         context = context[1:-1]\n",
    "\n",
    "\n",
    "#             entitys = list(set(entitys))   ### 去重，无所谓顺序，因为两两实体都会进行组合\n",
    "#     #         e1_e2 = []\n",
    "#             e_len = len(entitys)\n",
    "#             for i in range(e_len):\n",
    "#                 e1 = entitys[i]\n",
    "#                 for j in range(e_len):\n",
    "#                     if i == j:\n",
    "#                         continue\n",
    "#                     e2 = entitys[j]\n",
    "#                     line = e1+'，'+e2+'。'+context\n",
    "#                     lines.append(line)\n",
    "#         break\n",
    "        \n",
    "#         if count %5 == 0:\n",
    "#             print('loss: ',loss)\n",
    "#             out2 = torch.argmax(out,dim=2)\n",
    "#             batch_precision,batch_recall,batch_f1 = evaluate(out2,label_ids,input_mask)\n",
    "#             print('batch_precision:%.4f  batch_recall:%.4f  batch_f1: %.4f' %(batch_precision,batch_recall,batch_f1)) \n",
    "            \n",
    "#             bor_precision, bor_recall,bor_f1 = evaluate_bor(out2,label_ids,input_mask)\n",
    "#             print('bor_precision:%.4f  bor_recall:%.4f  bor_f1: %.4f' %(bor_precision,bor_recall,bor_f1)) \n",
    "#         print(lines)\n",
    "#         break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(str(e)+'：结束')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tris = []\n",
    "for other in others:\n",
    "    valid_tri = []\n",
    "    for eel in other:\n",
    "        \n",
    "        if eel[2] == 0:\n",
    "            break\n",
    "        valid_tri.append((entitys[eel[0]],entitys[eel[1]],id2tag[eel[2]]))\n",
    "    valid_tris.append(valid_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = others[0][0]\n",
    "\n",
    "entitys[a[1]]\n",
    "# entitys[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entitys[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = create_re_lines(out,label_ids,input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((a,input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
