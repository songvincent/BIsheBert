{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rawdata  --->  NER_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 原来是标注的原始文件，relations,entitys,等都有\n",
    "* 处理后是 source,target, 但是关系尚未标出 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 人名  Nh\n",
    "* 毒品 NDR\n",
    "* 其他都是O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O   0\n",
    "- traffic_in 1\n",
    "- sell_drugs_to 2\n",
    "- provide_shelter_for 3\n",
    "- posess          4     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {}\n",
    "tag2id['traffic_in'] = 0\n",
    "tag2id['sell_drugs_to'] = 1\n",
    "tag2id['provide_shelter_for'] = 2\n",
    "tag2id['posess'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "\n",
    "filename = 'multi_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prepath+filename,'r',encoding='gbk') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(lines[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_label(start,end,sym,label_list):\n",
    "    for i in range(start,end):\n",
    "        if i == start:\n",
    "            label_list[i] = 'B-'+sym\n",
    "#             print(label_list[i])\n",
    "        else:\n",
    "            label_list[i] = 'I-'+sym\n",
    "#     print(start,end,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_lines = []\n",
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    if len(sentText) > 510:\n",
    "        continue\n",
    "#         sentText = sentText[:510]\n",
    "#     print(sentText)\n",
    "    label = ['O']*len(sentText)\n",
    "#     print(len(sentText),type(label))\n",
    "    entityMentions = con['entityMentions']\n",
    "    for entity in entityMentions:\n",
    "        if entity['label'] == 'Nh' or entity['label'] == 'NDR':\n",
    "#             print(entity['start'])\n",
    "            update_label(entity['start'],entity['end'],entity['label'],label)\n",
    "    ner_line['source'] = sentText\n",
    "    ner_line['target'] = label\n",
    "#     ner_line['relations'] = []\n",
    "#     relationMentions = con['relationMentions']\n",
    "#     for relamen in relationMentions:\n",
    "#         entity1 = relamen['em1Text']\n",
    "#         e1start = relamen['e1start']\n",
    "#         entity2 = relamen['em2Text']\n",
    "#         e2start = relamen['e21start']\n",
    "#         label = relamen['label']\n",
    "#         ner_line['relations'].append([str(e1start)+'-'+str(len(entity1),tag2id[label],str(e2start)+'-'+str(len(entity2)]))\n",
    "#         ner_line['relations'].append(tag2id[label])\n",
    "#         ner_line['relations'].append(str(e2start)+'-'+str(len(entity2)))\n",
    "        \n",
    "    ner_lines.append(ner_line)\n",
    "#     print(con['entityMentions'])\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines),len(ner_lines)  ###除去了两个特长序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_lines[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "with open(prepath+filename.split('.')[0]+'ner.txt','w+',encoding = 'utf-8') as f:\n",
    "    for line in ner_lines:\n",
    "        line_str = json.dumps(line)\n",
    "        f.write(line_str+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计字数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "\n",
    "filename = 'multi_trainner.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(prepath+filename,'r',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text = []\n",
    "for line in lines:\n",
    "    line= line.strip()\n",
    "    con = json.loads(line)\n",
    "    sentText = con['source']\n",
    "#     print(sentText)\n",
    "    count_text.append(len(sentText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(count_text)) ## bert 句子长度设为512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rawdata  --->  RE_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepath = '../multi_data/'\n",
    "filename = 'multi_test.txt'\n",
    "\n",
    "with open(prepath+filename,'r',encoding='gbk') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020)\n",
    "##  注意，因为随机数的存在每次产生的数据都可能不一样,所以利用随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_lines = []\n",
    "re_lines = []\n",
    "# labels = []\n",
    "for line in lines:\n",
    "    ner_line = {}\n",
    "    con = json.loads(line)\n",
    "    sentText = con['sentText']\n",
    "    relationMentions = con['relationMentions']\n",
    "    triples = []\n",
    "    tuples = []\n",
    "    entitys = []\n",
    "#     e1s = []\n",
    "#     e2s = []\n",
    "    for relationMention in relationMentions:\n",
    "        e1 = relationMention['em1Text']\n",
    "        e2 = relationMention['em2Text']\n",
    "        label = relationMention['label']\n",
    "        triples.append((label,e1,e2))\n",
    "        tuples.append((e1,e2))\n",
    "        entitys.append(e1)\n",
    "        entitys.append(e2)\n",
    "    length = len(entitys)   \n",
    "    for i in range(5):\n",
    "        t1 = random.randint(0,length-1)\n",
    "        e1 = entitys[t1]\n",
    "        t2 = random.randint(0,length-1)\n",
    "        e2 = entitys[t2]\n",
    "        if (e1,e2) in tuples or e1==e2:\n",
    "            continue\n",
    "        if ('O',e1,e2) not in triples:\n",
    "            triples.append(('O',e1,e2))\n",
    "            \n",
    "#     print(triples)\n",
    "    \n",
    "    for lee in triples:\n",
    "        re_line ={}\n",
    "        line_label = lee[0]\n",
    "        res_line = lee[1]+'，'+lee[2]+'。'+sentText\n",
    "        if len(res_line) >510:\n",
    "            continue\n",
    "        re_line['source'] = res_line\n",
    "        re_line['target'] = line_label\n",
    "        re_lines.append(re_line)\n",
    "#         re_lines.append(res_line)\n",
    "#         labels.append(line_label)\n",
    "#         print()\n",
    "\n",
    "        \n",
    "#     break\n",
    "        \n",
    "    \n",
    "#     entityMentions = con['entityMentions']\n",
    "#     entitys = []\n",
    "#     for entity in entityMentions:\n",
    "#         if entity['label'] == 'Nh' or entity['label'] == 'NDR':\n",
    "#             ent_pos = (entity['text'],entity['start'])\n",
    "#             entitys.append(ent_pos)\n",
    "# #     entitys = entitys\n",
    "#     length = len(entitys)\n",
    "#     for i in range(length):\n",
    "#         e1,e2,label = get_label(i,length,entitys,relationMentions)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle (re_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': '冯某龄，冯某裕。阳江市江城区人民检察院指控，从2014年8月24日至9月19日，被告人冯某龄先后多次容留吸毒人员陈某存、冯某裕等人在冯某龄位于闸坡镇丹济村委会丹二社长行路兴福巷北151号的住所吸食毒品。后民警将冯某龄、冯某裕等人抓获。',\n",
       "  'target': 'provide_shelter_for'},\n",
       " {'source': '甲基苯丙胺，杨某。公诉机关指控，2016年10月14日上午，被告人杨某伙同他人在简阳市简城街道×一居民房中吸食了毒品甲基苯丙胺。当日12时许，当杨某离开行至简城街道龙王庙街时，被接群众举报赶到的民警挡获，民警从杨某上衣包内检查出净重为49.39克的疑似毒品甲基苯丙胺（俗称，“冰毒”）并予以扣押。',\n",
       "  'target': 'O'},\n",
       " {'source': '张某，甲基苯丙胺片剂。公诉机关指控：2015年8月21日0时许，被告人张某驾驶其车号为鄂a×××××的出租车到武汉市新洲区阳逻街东方新天地小区，以人民币200元的价格，将4颗甲基苯丙胺片剂（俗称“麻果”）卖给陈某。交易完成后，公安民警在阳逻街金融街路段将张某抓获，并于当日将其刑事拘留。经武汉市公安毒品司法鉴定中心鉴定，查获的4颗红色片剂均为毒品甲基苯丙胺，净重为0.38克，上述毒品已被公安机关收缴。公诉机关认为被告人张某具有自愿认罪的量刑情节，建议判处被告人张某拘役三个月左右，并处罚金。',\n",
       "  'target': 'traffic_in'},\n",
       " {'source': '甲基苯丙胺，武某。太原市小店区人民检察院指控，2016年1月30日11时许，在太原市小店区康宁街云鼎商务楼1号楼1号商铺内，被告人武某随身携带16小包净重15.5克毒品疑似物，被公安机关依法查获。经依法鉴定，毒品疑似物中均检出甲基苯丙胺成分。',\n",
       "  'target': 'O'},\n",
       " {'source': '陈某甲，陈某1。经审理查明，2014年3月至4月期间，被告人陈某1在枣阳市南关街其租住的房间内，先后三次容留陈某甲吸食毒品。2014年10月，陈某1在枣阳市大西街卫生巷的租住房间内，容留黄某吸食毒品，具体犯罪事实如下：',\n",
       "  'target': 'O'},\n",
       " {'source': '李绍某，甲基苯丙胺。公诉机关指控，2014年4月1日，被告人李绍某来到佛山市南海区大沥镇三鸟市场附近路段向一男子（另案处理）购回甲基苯丙胺、海洛因等毒品一批用于吸食。同月2日4时许，李绍某在南海区狮山镇松岗显东村一出租屋205房楼下被查获，民警当场从其身上起获疑似毒品一批。后民警在李绍某居住的狮山镇官窑黎岗豸下村三巷3号住宅内搜获疑似毒品一批。',\n",
       "  'target': 'posess'},\n",
       " {'source': '吴某，甲基苯丙胺。广州铁路运输检察院指控被告人吴某于2014年6月8日15时许，持当日t14次广州东至沈阳北火车票在广州东火车站二楼进站安检口准备进站乘车时，被民警从其所持的“louisvuiton”牌格子花纹钱包内查获两包疑似毒品的白色固体晶体。经鉴定，一包白色固体晶体净重23.27克，一包白色固体晶体净重20.34克，均含甲基苯丙胺成分。经现场胶体金法检测，吴某的尿液呈阳性。被告人吴某的行为触犯了《中华人民共和国刑法》第三百四十八条之规定，应当以非法持有毒品罪追究其刑事责任，建议判处其有期徒刑二年至二年六个月和并处罚金。检察机关提供了相应的证据。',\n",
       "  'target': 'posess'},\n",
       " {'source': '李绍某，海洛因。公诉机关指控，2014年4月1日，被告人李绍某来到佛山市南海区大沥镇三鸟市场附近路段向一男子（另案处理）购回甲基苯丙胺、海洛因等毒品一批用于吸食。同月2日4时许，李绍某在南海区狮山镇松岗显东村一出租屋205房楼下被查获，民警当场从其身上起获疑似毒品一批。后民警在李绍某居住的狮山镇官窑黎岗豸下村三巷3号住宅内搜获疑似毒品一批。',\n",
       "  'target': 'posess'},\n",
       " {'source': '俞培勇，王某某。经审理查明：2014年4月16日14时许，被告人俞培勇驾驶牌号为赣H1XXXX的朗逸轿车，至上海市宝山区大华三路XXX号恒凯宾馆，与王某某在该宾馆406房间内一同吸食毒品，被上海市公安局宝山分局民警当场抓获，并从其随身携带的包内缴获甲基苯丙胺0.72克。后在民警欲对被告人俞培勇驾驶车辆进行搜查时，其又主动交代了藏匿在该车辆左前车门内槽处的甲基苯丙胺54.62克。被告人俞培勇到案后对上述犯罪事实亦供认不讳。',\n",
       "  'target': 'O'},\n",
       " {'source': '海洛因，龚某。潜江市人民检察院指控，2014年6月19日16时许，潜江市公安局民警在潜江市泰丰办事处泰丰路欣然旅社303房将在此登记住宿的龚某抓获，当场从该房内查获含海洛因成分的灰色粉末净重11.726克。公诉机关针对指控的上述事实向法庭提交了相应证据。公诉机关认为，被告人龚某的行为构成非法持有毒品罪。公诉机关要求依照《中华人民共和国刑法》第三百四十八条之规定对被告人龚某予以判处。',\n",
       "  'target': 'O'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "with open(prepath+filename.split('.')[0]+'re.txt','w+',encoding = 'utf-8') as f:\n",
    "    for line in re_lines:\n",
    "        line_str = json.dumps(line)\n",
    "        f.write(line_str+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
